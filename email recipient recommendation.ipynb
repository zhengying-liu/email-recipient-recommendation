{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load \"baseline.py\"\n",
    "import random\n",
    "import operator\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "path_to_data = \"./\"\n",
    "\n",
    "##########################\n",
    "# load some of the files #                           \n",
    "##########################\n",
    "\n",
    "training = pd.read_csv(path_to_data + 'training_set.csv', sep=',', header=0)\n",
    "\n",
    "training_info = pd.read_csv(path_to_data + 'training_info.csv', sep=',', header=0)\n",
    "\n",
    "test = pd.read_csv(path_to_data + 'test_set.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>mids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>158713 158697 200301 158679 278595 298162 2002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amr.ibrahim@enron.com</td>\n",
       "      <td>215241 3437 215640 3506 191790 3517 3520 3562 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrea.ring@enron.com</td>\n",
       "      <td>270705 270706 270707 270708 270709 270710 2707...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sylvia.hu@enron.com</td>\n",
       "      <td>111444 111422 183084 111412 111347 110883 1105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phillip.platter@enron.com</td>\n",
       "      <td>327074 327384 327385 264443 274124 274125 2741...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sender  \\\n",
       "0    karen.buckley@enron.com   \n",
       "1      amr.ibrahim@enron.com   \n",
       "2      andrea.ring@enron.com   \n",
       "3        sylvia.hu@enron.com   \n",
       "4  phillip.platter@enron.com   \n",
       "\n",
       "                                                mids  \n",
       "0  158713 158697 200301 158679 278595 298162 2002...  \n",
       "1  215241 3437 215640 3506 191790 3517 3520 3562 ...  \n",
       "2  270705 270706 270707 270708 270709 270710 2707...  \n",
       "3  111444 111422 183084 111412 111347 110883 1105...  \n",
       "4  327074 327384 327385 264443 274124 274125 2741...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>2000-07-25 08:14:00</td>\n",
       "      <td>Legal has been assessing the risks of doing bl...</td>\n",
       "      <td>robert.badeer@enron.com murray.o neil@enron.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>2000-08-03 02:56:00</td>\n",
       "      <td>Attached is a spreadsheet to estimate export f...</td>\n",
       "      <td>kim.ward@enron.com robert.badeer@enron.com mur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>2000-08-15 05:37:00</td>\n",
       "      <td>Kevin/Bob: Here is a quick rundown on the cons...</td>\n",
       "      <td>robert.badeer@enron.com john.massey@enron.com ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>2000-08-20 14:12:00</td>\n",
       "      <td>check this out and let everyone know what s up...</td>\n",
       "      <td>robert.badeer@enron.com jeff.richter@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>2000-08-22 08:17:00</td>\n",
       "      <td>Further to your letter to us (addressed to Mr....</td>\n",
       "      <td>pgillman@schiffhardin.com kamarlantes@calpx.co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mid                 date  \\\n",
       "0   60  2000-07-25 08:14:00   \n",
       "1   66  2000-08-03 02:56:00   \n",
       "2   74  2000-08-15 05:37:00   \n",
       "3   80  2000-08-20 14:12:00   \n",
       "4   83  2000-08-22 08:17:00   \n",
       "\n",
       "                                                body  \\\n",
       "0  Legal has been assessing the risks of doing bl...   \n",
       "1  Attached is a spreadsheet to estimate export f...   \n",
       "2  Kevin/Bob: Here is a quick rundown on the cons...   \n",
       "3  check this out and let everyone know what s up...   \n",
       "4  Further to your letter to us (addressed to Mr....   \n",
       "\n",
       "                                          recipients  \n",
       "0  robert.badeer@enron.com murray.o neil@enron.co...  \n",
       "1  kim.ward@enron.com robert.badeer@enron.com mur...  \n",
       "2  robert.badeer@enron.com john.massey@enron.com ...  \n",
       "3     robert.badeer@enron.com jeff.richter@enron.com  \n",
       "4  pgillman@schiffhardin.com kamarlantes@calpx.co...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>mids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>298389 332383 298390 284071 366982 81773 81791...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amr.ibrahim@enron.com</td>\n",
       "      <td>48260 48465 50344 48268 50330 48237 189979 189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrea.ring@enron.com</td>\n",
       "      <td>366364 271168 271172 271167 271189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sylvia.hu@enron.com</td>\n",
       "      <td>134931 134856 233549 233517 134895 233584 3736...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phillip.platter@enron.com</td>\n",
       "      <td>274220 274225 274215 274223 274214 274207 2742...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sender  \\\n",
       "0    karen.buckley@enron.com   \n",
       "1      amr.ibrahim@enron.com   \n",
       "2      andrea.ring@enron.com   \n",
       "3        sylvia.hu@enron.com   \n",
       "4  phillip.platter@enron.com   \n",
       "\n",
       "                                                mids  \n",
       "0  298389 332383 298390 284071 366982 81773 81791...  \n",
       "1  48260 48465 50344 48268 50330 48237 189979 189...  \n",
       "2                 366364 271168 271172 271167 271189  \n",
       "3  134931 134856 233549 233517 134895 233584 3736...  \n",
       "4  274220 274225 274215 274223 274214 274207 2742...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "# create some handy structures #                    \n",
    "################################\n",
    "                            \n",
    "# convert training set to dictionary\n",
    "emails_ids_per_sender = {}\n",
    "for index, series in training.iterrows():\n",
    "    row = series.tolist()\n",
    "    sender = row[0]\n",
    "    ids = row[1:][0].split(' ')\n",
    "    emails_ids_per_sender[sender] = ids\n",
    "\n",
    "# save all unique sender names\n",
    "all_senders = emails_ids_per_sender.keys()\n",
    "\n",
    "# create address book with frequency information for each user\n",
    "address_books = {}\n",
    "i = 0\n",
    "\n",
    "for sender, ids in emails_ids_per_sender.items():\n",
    "    recs_temp = []\n",
    "    for my_id in ids:\n",
    "        recipients = training_info[training_info['mid']==int(my_id)]['recipients'].tolist()\n",
    "        recipients = recipients[0].split(' ')\n",
    "        # keep only legitimate email addresses\n",
    "        recipients = [rec for rec in recipients if '@' in rec]\n",
    "        recs_temp.append(recipients)\n",
    "    # flatten    \n",
    "    recs_temp = [elt for sublist in recs_temp for elt in sublist]\n",
    "    # compute recipient counts\n",
    "    rec_occ = dict(Counter(recs_temp))\n",
    "    # order by frequency\n",
    "    sorted_rec_occ = sorted(rec_occ.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    # save\n",
    "    address_books[sender] = sorted_rec_occ\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    i += 1\n",
    "  \n",
    "# save all unique recipient names    \n",
    "all_recs = list(set([elt[0] for sublist in address_books.values() for elt in sublist]))\n",
    "\n",
    "# save all unique user names \n",
    "all_users = []\n",
    "all_users.extend(all_senders)\n",
    "all_users.extend(all_recs)\n",
    "all_users = list(set(all_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############\n",
    "# baselines #                           \n",
    "#############\n",
    "\n",
    "# will contain email ids, predictions for random baseline, and predictions for frequency baseline\n",
    "predictions_per_sender = {}\n",
    "\n",
    "# number of recipients to predict\n",
    "k = 10\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    name_ids = row.tolist()\n",
    "    sender = name_ids[0]\n",
    "    # get IDs of the emails for which recipient prediction is needed\n",
    "    ids_predict = name_ids[1].split(' ')\n",
    "    ids_predict = [int(my_id) for my_id in ids_predict]\n",
    "    random_preds = []\n",
    "    freq_preds = []\n",
    "    # select k most frequent recipients for the user\n",
    "    k_most = [elt[0] for elt in address_books[sender][:k]]\n",
    "    for id_predict in ids_predict:\n",
    "        # select k users at random\n",
    "        random_preds.append(random.sample(all_users, k))\n",
    "        # for the frequency baseline, the predictions are always the same\n",
    "        freq_preds.append(k_most)\n",
    "    predictions_per_sender[sender] = [ids_predict,random_preds,freq_preds]\t\n",
    "\n",
    "#################################################\n",
    "# write predictions in proper format for Kaggle #                           \n",
    "#################################################\n",
    "\n",
    "path_to_results = \"./\"\n",
    "\n",
    "with open(path_to_results + 'predictions_random.txt', 'w') as my_file:\n",
    "    my_file.write('mid,recipients' + '\\n')\n",
    "    for sender, preds in predictions_per_sender.items():\n",
    "        ids = preds[0]\n",
    "        random_preds = preds[1]\n",
    "        for index, my_preds in enumerate(random_preds):\n",
    "            my_file.write(str(ids[index]) + ',' + ' '.join(my_preds) + '\\n')\n",
    "\n",
    "with open(path_to_results + 'predictions_frequency.txt', 'w') as my_file:\n",
    "    my_file.write('mid,recipients' + '\\n')\n",
    "    for sender, preds in predictions_per_sender.items():\n",
    "        ids = preds[0]\n",
    "        freq_preds = preds[2]\n",
    "        for index, my_preds in enumerate(freq_preds):\n",
    "            my_file.write(str(ids[index]) + ',' + ' '.join(my_preds) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43613, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Legal has been assessing the risks of doing bl...\n",
       "1        Attached is a spreadsheet to estimate export f...\n",
       "2        Kevin/Bob: Here is a quick rundown on the cons...\n",
       "3        check this out and let everyone know what s up...\n",
       "4        Further to your letter to us (addressed to Mr....\n",
       "5        The new version of the EnronOnline website is ...\n",
       "6        Check this out.  I think that we need to be si...\n",
       "7        We have had some confusion recently with respe...\n",
       "8        I will be traveling to Calgary on Tuesday and ...\n",
       "9        Please note that the EnronOnline Phase 2 train...\n",
       "10       Recently, there have been several questions re...\n",
       "11       Please see the attached.  Christian, could you...\n",
       "12       i would categorize things in the following man...\n",
       "13       put this into the congestion redesign file if ...\n",
       "14       Alaska Producers Say Gas Pipeline Would Be Too...\n",
       "15       Canadian Arctic Exploration Moves Full Steam A...\n",
       "16       Producers Indicate North Slope s Beaufort Rout...\n",
       "17       CERA Analyst Gives Alaska Gas Pipe 60% Chance ...\n",
       "18       Foothills CEOs Says Canada to Gain With Alaska...\n",
       "19       Eric,FYI--One of the Iowa congresswomen told u...\n",
       "20       Note:  I had been sending the Arctic market in...\n",
       "21       Jon, I was referring to the actual monument si...\n",
       "22       Scott, I shold probably clearify something.  T...\n",
       "23       Kevin, I apologize for not getting back to you...\n",
       "24       Kevin, as promised, attached is the informatio...\n",
       "25       Regent Energy in Pact to Develop 500 MW Plant ...\n",
       "26                   <Embedded Microsoft Graph 2000 Chart>\n",
       "27       Kevin,Attached are electricity price discovery...\n",
       "28       Kevin,Attached are two files with 10 years of ...\n",
       "29       Here is a revised version of the Red Rock agre...\n",
       "                               ...                        \n",
       "43583    X-FileName: As most people are aware, there ar...\n",
       "43584    X-FileName: fyi-----Original Message-----From:...\n",
       "43585    X-FileName: This e-mail is to confirm what we ...\n",
       "43586    __________________I have discussed with Doug G...\n",
       "43587    Doug -- Following up on our discussion, attach...\n",
       "43588    Attached is a draft response to the Frontera N...\n",
       "43589    Attached are new draft responses to the Fronte...\n",
       "43590    ERCOT Delivery Points have been set up as foll...\n",
       "43591    Make sure we attend these sessions.-----------...\n",
       "43592    Following discussions with you and Doug, attac...\n",
       "43593    Hello!You have been identified by your manager...\n",
       "43594    FYI. -----Original Message-----From: \\tRodrigu...\n",
       "43595    Howdy all!Just a reminder that Steve Swain and...\n",
       "43596    Bike Teams Please join us in Mt Hood 11:30 - 1...\n",
       "43597    CONGRATULATIONS ALL WHO PARTICIPATED IN THE SE...\n",
       "43598    Before I leave today, I just wanted to say wha...\n",
       "43599    This information was sent by Tim Belden and Ch...\n",
       "43600    Please note that Chris Calger is in a meeting ...\n",
       "43601    HR is wishing you a Happy Friday! We ve got so...\n",
       "43602    If you work in West Power Trading, congratulat...\n",
       "43603    Hello again!You have been identified by your m...\n",
       "43604    Just a reminder about the brown bag meeting fo...\n",
       "43605    We are pleased to announce the arrival of Kara...\n",
       "43606    You are invited to attend a meeting at 3:00 p....\n",
       "43607    Howdy all!We currently have an opening in the ...\n",
       "43608    FYI--The information below is an excellent ove...\n",
       "43609      FERC is holding a week-long conference on Re...\n",
       "43610    X-FileName: During the past few days several p...\n",
       "43611    X-FileName: Enron announces $1 billion of addi...\n",
       "43612    X-FileName: Enron s General Counsel sent out a...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_info[\"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-FileName: fyi-----Original Message-----From: Ingersoll, Richard Sent: Tuesday, September 25, 2001 8:16 AMTo: Belden, TimSubject: FW: Standards Announcement-----Original Message-----From: elder@wscc.com [mailto:elder@wscc.com]Sent: Monday, September 24, 2001 4:06 PMTo: WSCC Standards AnnouncementSubject: Standards AnnouncementWSCC STANDARDS CORRESPONDENTSWESTERN MARKET INTERFACE COMMITTEECOMPLIANCE PROCESS TASK FORCEOPERATIONS COMMITTEE AND   OC SUBCOMMITTEESPLANNING COORDINATION COMMITTEE AND  PCC SUBCOMMITTEESIn accordance with the WSCC \"Process for Developing and Approving WSCC Standards.\" the \"Procedures for Regional Planning Project Review and Rating Transmission Facilities\" has been posted for approval on the WSCC Web site (http://www.wscc.com/files/newrppr6.pdf). Approval of the document will be requested at the October 25-26, 2001 PCC meeting.LINDA ELDERADMINISTRATIVE COORDINATORPH 801-582-0353FX 801-582-3918EM elder@wscc.com\n"
     ]
    }
   ],
   "source": [
    "print(training_info[\"body\"][43584])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn\n",
      "\n",
      "DESCRIPTION\n",
      "    Machine learning module for Python\n",
      "    ==================================\n",
      "    \n",
      "    sklearn is a Python module integrating classical machine\n",
      "    learning algorithms in the tightly-knit world of scientific Python\n",
      "    packages (numpy, scipy, matplotlib).\n",
      "    \n",
      "    It aims to provide simple and efficient solutions to learning problems\n",
      "    that are accessible to everybody and reusable in various contexts:\n",
      "    machine-learning as a versatile tool for science and engineering.\n",
      "    \n",
      "    See http://scikit-learn.org for complete documentation.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __check_build (package)\n",
      "    _build_utils (package)\n",
      "    _isotonic\n",
      "    base\n",
      "    calibration\n",
      "    cluster (package)\n",
      "    covariance (package)\n",
      "    cross_decomposition (package)\n",
      "    cross_validation\n",
      "    datasets (package)\n",
      "    decomposition (package)\n",
      "    discriminant_analysis\n",
      "    dummy\n",
      "    ensemble (package)\n",
      "    exceptions\n",
      "    externals (package)\n",
      "    feature_extraction (package)\n",
      "    feature_selection (package)\n",
      "    gaussian_process (package)\n",
      "    grid_search\n",
      "    isotonic\n",
      "    kernel_approximation\n",
      "    kernel_ridge\n",
      "    lda\n",
      "    learning_curve\n",
      "    linear_model (package)\n",
      "    manifold (package)\n",
      "    metrics (package)\n",
      "    mixture (package)\n",
      "    model_selection (package)\n",
      "    multiclass\n",
      "    multioutput\n",
      "    naive_bayes\n",
      "    neighbors (package)\n",
      "    neural_network (package)\n",
      "    pipeline\n",
      "    preprocessing (package)\n",
      "    qda\n",
      "    random_projection\n",
      "    semi_supervised (package)\n",
      "    setup\n",
      "    svm (package)\n",
      "    tests (package)\n",
      "    tree (package)\n",
      "    utils (package)\n",
      "\n",
      "FUNCTIONS\n",
      "    clone(estimator, safe=True)\n",
      "        Constructs a new estimator with the same parameters.\n",
      "        \n",
      "        Clone does a deep copy of the model in an estimator\n",
      "        without actually copying attached data. It yields a new estimator\n",
      "        with the same parameters that has not been fit on any data.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator: estimator object, or list, tuple or set of objects\n",
      "            The estimator or group of estimators to be cloned\n",
      "        \n",
      "        safe: boolean, optional\n",
      "            If safe is false, clone will fall back to a deepcopy on objects\n",
      "            that are not estimators.\n",
      "\n",
      "DATA\n",
      "    __SKLEARN_SETUP__ = False\n",
      "    __all__ = ['calibration', 'cluster', 'covariance', 'cross_decompositio...\n",
      "\n",
      "VERSION\n",
      "    0.18\n",
      "\n",
      "FILE\n",
      "    /Users/Evariste/anaconda3/lib/python3.5/site-packages/sklearn/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note:  Good update on U.S. and Canadian supply trends. -----Original Message-----From: CERA Webmaster [mailto:webmaster@CERA.com]Sent: Wednesday, July 18, 2001 11:19 AMTo: InsightsSubject: North American Gas Productive Capacity Is Expanding - CERA Decision Brief Title: Natural Gas Productive Capacity Outlook in North America--How Fast Can It Grow? URL(s): <http://www20.cera.com/eprofile?u=35&m=2564> *********************************************************************** NORTH AMERICAN GAS PRODUCTIVE CAPACITY IS EXPANDING The effect of record gas-related drilling is becoming increasingly evident in both the United States and Canada. Key themes explored in this Decision Brief include *  the extent of the rebound in the US lower-48 and Canadian gas supply *  the outlook for US lower-48 and Canadian supply to 2005 *  underlying trends likely to constrain production growth *  the sources of new supply   *  uncertainties in the outlook through 2005: upside potential and downside threats *  possible effect of the decline in gas prices **end** Follow above URL for complete CERA Decision Brief (20 printed pages). E-mail Category: Decision Brief                                    CERA Knowledge Area(s): North American Gas *********************************************************************** To make changes to your cera.com profile go to: <http://www20.cera.com/client/updateaccount> Forgot your username and password? Go to: <http://www20.cera.com/client/forgot> This electronic message and attachments, if any, contain information from Cambridge Energy Research Associates, Inc. (CERA) which is confidential and may be privileged. Unauthorized disclosure, copying, distribution or use of the contents of this message or any attachments, in whole or in part, is strictly prohibited. Terms of Use: <http://www20.cera.com/tos> Questions/Comments: webmaster@cera.com Copyright 2001. Cambridge Energy Research Associates\n"
     ]
    }
   ],
   "source": [
    "example = training_info.body[42]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note:  Good update on U.S. and Canadian supply trends. -----Original Message-----From: CERA Webmaster [mailto:webmaster@CERA.com]Sent: Wednesday, July 18, 2001 11:19 AMTo: InsightsSubject: North American Gas Productive Capacity Is Expanding - CERA Decision Brief Title: Natural Gas Productive Capacity Outlook in North America--How Fast Can It Grow? URL(s):  *********************************************************************** NORTH AMERICAN GAS PRODUCTIVE CAPACITY IS EXPANDING The effect of record gas-related drilling is becoming increasingly evident in both the United States and Canada. Key themes explored in this Decision Brief include *  the extent of the rebound in the US lower-48 and Canadian gas supply *  the outlook for US lower-48 and Canadian supply to 2005 *  underlying trends likely to constrain production growth *  the sources of new supply   *  uncertainties in the outlook through 2005: upside potential and downside threats *  possible effect of the decline in gas prices **end** Follow above URL for complete CERA Decision Brief (20 printed pages). E-mail Category: Decision Brief                                    CERA Knowledge Area(s): North American Gas *********************************************************************** To make changes to your cera.com profile go to:  Forgot your username and password? Go to:  This electronic message and attachments, if any, contain information from Cambridge Energy Research Associates, Inc. (CERA) which is confidential and may be privileged. Unauthorized disclosure, copying, distribution or use of the contents of this message or any attachments, in whole or in part, is strictly prohibited. Terms of Use:  Questions/Comments: webmaster@cera.com Copyright 2001. Cambridge Energy Research Associates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Evariste/anaconda3/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /Users/Evariste/anaconda3/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup             \n",
    "\n",
    "print(BeautifulSoup(example).get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re \n",
    "import itertools\n",
    "import igraph\n",
    "import nltk\n",
    "import operator\n",
    "from nltk.corpus import stopwords\n",
    "# requires nltk 3.2.1\n",
    "from nltk import pos_tag\n",
    "\n",
    "\n",
    "def clean_text_simple(text, remove_stopwords=True, pos_filtering=True, stemming=True):\n",
    "    \n",
    "    punct = string.punctuation.replace('-', '')\n",
    "    \n",
    "    # convert to lower case\n",
    "    text = text.lower()\n",
    "    # remove punctuation (preserving intra-word dashes)\n",
    "    text = ''.join(l for l in text if l not in punct)\n",
    "    # strip extra white space\n",
    "    text = re.sub(' +',' ',text)\n",
    "    # strip leading and trailing white space\n",
    "    text = text.strip()\n",
    "    # tokenize (split based on whitespace)\n",
    "    ### fill the gap ###\n",
    "    tokens = text.split(' ')\n",
    "    if pos_filtering == True:\n",
    "        # apply POS-tagging\n",
    "        tagged_tokens = pos_tag(tokens)\n",
    "        # retain only nouns and adjectives\n",
    "        tokens_keep = []\n",
    "        for i in range(len(tagged_tokens)):\n",
    "            item = tagged_tokens[i]\n",
    "            if (\n",
    "            item[1] == 'NN' or\n",
    "            item[1] == 'NNS' or\n",
    "            item[1] == 'NNP' or\n",
    "            item[1] == 'NNPS' or\n",
    "            item[1] == 'JJ' or\n",
    "            item[1] == 'JJS' or\n",
    "            item[1] == 'JJR'\n",
    "            ):\n",
    "                tokens_keep.append(item[0])\n",
    "        tokens = tokens_keep\n",
    "    if remove_stopwords:\n",
    "        stpwds = stopwords.words('english')\n",
    "        # remove stopwords\n",
    "        tokens = [t for t in tokens if t not in stpwds]\n",
    "    if stemming:\n",
    "        stemmer = nltk.stem.PorterStemmer()\n",
    "        # apply Porter's stemmer\n",
    "        tokens_stemmed = list()\n",
    "        for token in tokens:\n",
    "            tokens_stemmed.append(stemmer.stem(token))\n",
    "        tokens = tokens_stemmed\n",
    "\n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note:  Good update on U.S. and Canadian supply trends. -----Original Message-----From: CERA Webmaster [mailto:webmaster@CERA.com]Sent: Wednesday, July 18, 2001 11:19 AMTo: InsightsSubject: North American Gas Productive Capacity Is Expanding - CERA Decision Brief Title: Natural Gas Productive Capacity Outlook in North America--How Fast Can It Grow? URL(s): <http://www20.cera.com/eprofile?u=35&m=2564> *********************************************************************** NORTH AMERICAN GAS PRODUCTIVE CAPACITY IS EXPANDING The effect of record gas-related drilling is becoming increasingly evident in both the United States and Canada. Key themes explored in this Decision Brief include *  the extent of the rebound in the US lower-48 and Canadian gas supply *  the outlook for US lower-48 and Canadian supply to 2005 *  underlying trends likely to constrain production growth *  the sources of new supply   *  uncertainties in the outlook through 2005: upside potential and downside threats *  possible effect of the decline in gas prices **end** Follow above URL for complete CERA Decision Brief (20 printed pages). E-mail Category: Decision Brief                                    CERA Knowledge Area(s): North American Gas *********************************************************************** To make changes to your cera.com profile go to: <http://www20.cera.com/client/updateaccount> Forgot your username and password? Go to: <http://www20.cera.com/client/forgot> This electronic message and attachments, if any, contain information from Cambridge Energy Research Associates, Inc. (CERA) which is confidential and may be privileged. Unauthorized disclosure, copying, distribution or use of the contents of this message or any attachments, in whole or in part, is strictly prohibited. Terms of Use: <http://www20.cera.com/tos> Questions/Comments: webmaster@cera.com Copyright 2001. Cambridge Energy Research Associates\n"
     ]
    }
   ],
   "source": [
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'updat',\n",
       " 'canadian',\n",
       " 'suppli',\n",
       " '-----origin',\n",
       " 'message-----from',\n",
       " 'cera',\n",
       " 'webmast',\n",
       " 'mailtowebmasterceracoms',\n",
       " 'wednesday',\n",
       " 'amto',\n",
       " 'insightssubject',\n",
       " 'north',\n",
       " 'american',\n",
       " 'ga',\n",
       " 'product',\n",
       " 'capac',\n",
       " 'cera',\n",
       " 'decis',\n",
       " 'brief',\n",
       " 'titl',\n",
       " 'natur',\n",
       " 'ga',\n",
       " 'product',\n",
       " 'capac',\n",
       " 'outlook',\n",
       " 'north',\n",
       " 'america--how',\n",
       " 'fast',\n",
       " 'url',\n",
       " 'httpwww20ceracomeprofileu35m2564',\n",
       " 'north',\n",
       " 'american',\n",
       " 'ga',\n",
       " 'product',\n",
       " 'capac',\n",
       " 'effect',\n",
       " 'record',\n",
       " 'gas-rel',\n",
       " 'drill',\n",
       " 'evid',\n",
       " 'unit',\n",
       " 'state',\n",
       " 'canada',\n",
       " 'key',\n",
       " 'theme',\n",
       " 'decis',\n",
       " 'brief',\n",
       " 'extent',\n",
       " 'rebound',\n",
       " 'lower-48',\n",
       " 'canadian',\n",
       " 'ga',\n",
       " 'suppli',\n",
       " 'outlook',\n",
       " 'lower-48',\n",
       " 'canadian',\n",
       " 'suppli',\n",
       " 'trend',\n",
       " 'like',\n",
       " 'product',\n",
       " 'growth',\n",
       " 'sourc',\n",
       " 'new',\n",
       " 'suppli',\n",
       " 'uncertainti',\n",
       " 'outlook',\n",
       " 'upsid',\n",
       " 'potenti',\n",
       " 'downsid',\n",
       " 'threat',\n",
       " 'possibl',\n",
       " 'effect',\n",
       " 'declin',\n",
       " 'ga',\n",
       " 'price',\n",
       " 'url',\n",
       " 'complet',\n",
       " 'cera',\n",
       " 'decis',\n",
       " 'brief',\n",
       " 'page',\n",
       " 'e-mail',\n",
       " 'categori',\n",
       " 'decis',\n",
       " 'brief',\n",
       " 'cera',\n",
       " 'knowledg',\n",
       " 'area',\n",
       " 'north',\n",
       " 'american',\n",
       " 'ga',\n",
       " 'chang',\n",
       " 'ceracom',\n",
       " 'profil',\n",
       " 'usernam',\n",
       " 'password',\n",
       " 'electron',\n",
       " 'messag',\n",
       " 'attach',\n",
       " 'contain',\n",
       " 'inform',\n",
       " 'cambridg',\n",
       " 'energi',\n",
       " 'research',\n",
       " 'cera',\n",
       " 'confidenti',\n",
       " 'unauthor',\n",
       " 'disclosur',\n",
       " 'distribut',\n",
       " 'use',\n",
       " 'content',\n",
       " 'messag',\n",
       " 'attach',\n",
       " 'whole',\n",
       " 'part',\n",
       " 'term',\n",
       " 'use',\n",
       " 'httpwww20ceracomto',\n",
       " 'questionscom',\n",
       " 'copyright',\n",
       " 'cambridg',\n",
       " 'energi',\n",
       " 'research',\n",
       " 'associ']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_simple(example, stemming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " 'should',\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " 'couldn',\n",
       " 'didn',\n",
       " 'doesn',\n",
       " 'hadn',\n",
       " 'hasn',\n",
       " 'haven',\n",
       " 'isn',\n",
       " 'ma',\n",
       " 'mightn',\n",
       " 'mustn',\n",
       " 'needn',\n",
       " 'shan',\n",
       " 'shouldn',\n",
       " 'wasn',\n",
       " 'weren',\n",
       " 'won',\n",
       " 'wouldn']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}